{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assuming we achieved pretty good accuracy during the training and testing phases, we can now use the trained model for inference &mdash; in other words, to predict the classification of images that the network has never seen before.\n",
        "\n",
        "But before we move on, we'll load the code you've already seen in previous notebooks:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "!wget -Nq https://raw.githubusercontent.com/MicrosoftDocs/tensorflow-learning-path/main/intro-keras/kintro.py\n",
        "from kintro import *"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember that in the previous notebook, after successfully training our network, we saved the weights of the model. We can now reconstruct a trained model using those weights."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "model = NeuralNetwork()\n",
        "model.load_weights('outputs/weights').expect_partial()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fbc584dbd90>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making a prediction is easy &mdash; we simply call the model's `predict` method and pass it some images. The true power of a neural network is its ability to make predictions for data that has not been seen during training or testing. But for the sake of simplicity, we'll demonstrate how prediction works by re-using a few of the images that we used during testing. The code below retrieves the first three images in our test data and uses them to make predictions. We then print the actual and predicted labels."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "batch_size = 64\n",
        "\n",
        "(_, test_dataset) = get_data(batch_size)\n",
        "(X_batch, actual_index_batch) = test_dataset.as_numpy_iterator().next()\n",
        "X = X_batch[0:3, :, :]\n",
        "actual_indices = actual_index_batch[0:3]\n",
        "\n",
        "predictions = model.predict(X)\n",
        "\n",
        "print('\\nPredicting:')\n",
        "for (actual_index, prediction) in zip(actual_indices, predictions):\n",
        "  actual_name = labels_map[actual_index]\n",
        "  predicted_index = tf.math.argmax(prediction).numpy()\n",
        "  predicted_name = labels_map[predicted_index]\n",
        "  print(f'Actual: {actual_name}, Predicted: {predicted_name}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicting:\n",
            "Actual: Bag, Predicted: Dress\n",
            "Actual: Sneaker, Predicted: Sneaker\n",
            "Actual: Ankle Boot, Predicted: Ankle Boot\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "With only two epochs of training, our network isn't very accurate, but it should get at least two out of three predictions right. You can increase the number of epochs in the training phase to get better predictions.\n",
        "\n",
        "Note that you can also get probabilities of the input image being of a certain class, in which case we need to normalize the output of our network using `softmax` to get probabilities. Here are the predictions for the first image in our test set: "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "probs = tf.nn.softmax(predictions[0])\n",
        "for i,p in enumerate(probs):\n",
        "    print(f'{labels_map[i]} -> {p:.3f}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T-Shirt -> 0.102\n",
            "Trouser -> 0.002\n",
            "Pullover -> 0.001\n",
            "Dress -> 0.870\n",
            "Coat -> 0.001\n",
            "Sandal -> 0.000\n",
            "Shirt -> 0.023\n",
            "Sneaker -> 0.000\n",
            "Bag -> 0.001\n",
            "Ankle Boot -> 0.000\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you need to compute probabilities often, you can specify `activation='softmax'` for the final `Dense` layer of your network. In this case the network would give you probabilities as output, and you need to omit `use_logits=True` in the `SparseCategoricalCrossentropy` loss function. "
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "a7d8d32a02de2fe32a77a4e581138922e011c09664b6c2991156e76c4176efab"
    },
    "kernelspec": {
      "display_name": "py37_tensorflow",
      "language": "python",
      "name": "conda-env-py37_tensorflow-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}