{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import gzip\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from typing import Tuple"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's start by including the code that gets the data and model, which you should be very familiar with by now."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "labels_map = {\n",
    "    0: 'T-Shirt',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle Boot',\n",
    "  }\n",
    "\n",
    "\n",
    "def read_images(path: str, image_size: int, num_items: int) -> np.ndarray:\n",
    "  f = gzip.open(path,'r')\n",
    "  buf = f.read(image_size * image_size * num_items)\n",
    "  data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "  data = data.reshape(num_items, image_size, image_size)\n",
    "  return data\n",
    "\n",
    "\n",
    "def read_labels(path: str, num_items: int) -> np.ndarray:\n",
    "  f = gzip.open(path,'r')\n",
    "  f.read(8)\n",
    "  buf = f.read(num_items)\n",
    "  data = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "  data = data.reshape(num_items)\n",
    "  return data\n",
    "\n",
    "\n",
    "def get_data(batch_size: int) -> Tuple[tf.data.Dataset, tf.data.Dataset]:\n",
    "  image_size = 28\n",
    "  num_train = 60000\n",
    "  num_test = 10000\n",
    "\n",
    "  training_images = read_images('data/FashionMNIST/raw/train-images-idx3-ubyte.gz', image_size, num_train)\n",
    "  test_images = read_images('data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz', image_size, num_test)\n",
    "  training_labels = read_labels('data/FashionMNIST/raw/train-labels-idx1-ubyte.gz', num_train)\n",
    "  test_labels = read_labels('data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz', num_test)\n",
    "\n",
    "  # (training_images, training_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "  train_dataset = tf.data.Dataset.from_tensor_slices((training_images, training_labels))\n",
    "  test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "\n",
    "  train_dataset = train_dataset.map(lambda image, label: (float(image) / 255.0, label))\n",
    "  test_dataset = test_dataset.map(lambda image, label: (float(image) / 255.0, label))\n",
    "\n",
    "  train_dataset = train_dataset.batch(batch_size).shuffle(500)\n",
    "  test_dataset = test_dataset.batch(batch_size).shuffle(500)\n",
    "\n",
    "  return (train_dataset, test_dataset)\n",
    "\n",
    "\n",
    "def get_model() -> tf.keras.Model:\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "  ])\n",
    "  return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to make a prediction, we need to pass some data to the model, and do a single forward pass through the network to get the prediction. If the code below is unclear to you, make sure you go back to module 1, where we explain it in detail. Remember that, unlike during testing, we don't need to call the loss function because we're no longer interested in evaluating how well the model is doing. Instead, we call `softmax` to convert the values of the output vector into values between 0 and 1, and then get the `argmax` of that vector to get the predicted label index.\n",
    "\n",
    "Similarly to the training and testing sections, once we're done with debugging, we can add a `@tf.function` decorator to get the performance benefits of graph execution."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "@tf.function\n",
    "def predict(model: tf.keras.Model, X: np.ndarray) -> tf.Tensor:\n",
    "  y_prime = model(X, training=False)\n",
    "  probabilities = tf.nn.softmax(y_prime, axis=1)\n",
    "  predicted_indices = tf.math.argmax(input=probabilities, axis=1)\n",
    "  return predicted_indices"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Typically, during inference, we give the model input data that it hasn't seen before. In this sample, for simplicity, we input the first 3 images of the test dataset instead. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "batch_size = 64\n",
    "\n",
    "model = get_model()\n",
    "model.load_weights('outputs/weights')\n",
    "\n",
    "(_, test_dataset) = get_data(batch_size)\n",
    "(X_batch, actual_index_batch) = next(test_dataset.as_numpy_iterator())\n",
    "X = X_batch[0:3, :, :]\n",
    "actual_indices = actual_index_batch[0:3]\n",
    "\n",
    "predicted_indices = predict(model, X)\n",
    "\n",
    "print('\\nPredicting:')\n",
    "for (actual_index, predicted_index) in zip(actual_indices, predicted_indices):\n",
    "  actual_name = labels_map[actual_index]\n",
    "  predicted_name = labels_map[predicted_index.numpy()]\n",
    "  print(f'Actual: {actual_name}, Predicted: {predicted_name}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Predicting:\n",
      "Actual: Sandal, Predicted: Sandal\n",
      "Actual: T-Shirt, Predicted: T-Shirt\n",
      "Actual: Bag, Predicted: Bag\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7d8d32a02de2fe32a77a4e581138922e011c09664b6c2991156e76c4176efab"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('fashion-tf': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}